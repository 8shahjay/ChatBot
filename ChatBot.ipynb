{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiyZlDqbnZTL19Y7BUMZgK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newtonxp/ChatBot/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ChatBot**\n",
        "\n",
        "- Meet my Python chatbot, trained on neural networks, designed to give you a brief insight into who I am.\n",
        "- This interactive bot engages in conversation, sharing essential details about my educational and professional background, expertise, and interests.\n",
        "- With its natural language processing capabilities, it ensures a seamless experience while responding to various queries. Ask about my education, work, or hobbies, and let this chatbot introduce me in a unique and engaging way."
      ],
      "metadata": {
        "id": "_TOpWu4GSYEb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** Due to some bugs in tflearn, it does not work well with the recent python update. So, you'll need to install python 3.6 for this project."
      ],
      "metadata": {
        "id": "VgCP32oQUh1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first install python 3.6\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.6\n",
        "# change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 1\n",
        "# select python version\n",
        "!sudo update-alternatives --config python3\n",
        "# check python version\n",
        "!python --version\n",
        "# install pip for new python\n",
        "!sudo apt-get install python3.6-distutils\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "!python get-pip.py\n",
        "# upgrade pip\n",
        "!sudo apt install python3-pip\n",
        "!python -m pip install --upgrade pip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlaZBvVGemxh",
        "outputId": "5fcc25b0-d579-4083-bb59-4669b4932f19"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [43.3 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [850 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,235 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,103 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [21.7 kB]\n",
            "Fetched 3,612 kB in 2s (1,556 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'libcasa-python3-6' for regex 'python3.6'\n",
            "Note, selecting 'libpython3.6-stdlib' for regex 'python3.6'\n",
            "Note, selecting 'python3.6-2to3' for regex 'python3.6'\n",
            "The following additional packages will be installed:\n",
            "  libcasa-casa6\n",
            "The following NEW packages will be installed:\n",
            "  libcasa-casa6 libcasa-python3-6\n",
            "0 upgraded, 2 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 1,088 kB of archives.\n",
            "After this operation, 4,238 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcasa-casa6 amd64 3.4.0-2build1 [1,000 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcasa-python3-6 amd64 3.4.0-2build1 [88.2 kB]\n",
            "Fetched 1,088 kB in 1s (1,213 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libcasa-casa6:amd64.\n",
            "(Reading database ... 120511 files and directories currently installed.)\n",
            "Preparing to unpack .../libcasa-casa6_3.4.0-2build1_amd64.deb ...\n",
            "Unpacking libcasa-casa6:amd64 (3.4.0-2build1) ...\n",
            "Selecting previously unselected package libcasa-python3-6:amd64.\n",
            "Preparing to unpack .../libcasa-python3-6_3.4.0-2build1_amd64.deb ...\n",
            "Unpacking libcasa-python3-6:amd64 (3.4.0-2build1) ...\n",
            "Setting up libcasa-casa6:amd64 (3.4.0-2build1) ...\n",
            "Setting up libcasa-python3-6:amd64 (3.4.0-2build1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "update-alternatives: error: alternative path /usr/bin/python3.6 doesn't exist\n",
            "update-alternatives: error: no alternatives for python3\n",
            "Python 3.10.12\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python3.6-distutils\n",
            "E: Couldn't find any package by glob 'python3.6-distutils'\n",
            "E: Couldn't find any package by regex 'python3.6-distutils'\n",
            "--2023-08-07 23:16:07--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2605506 (2.5M) [text/x-python]\n",
            "Saving to: ‘get-pip.py’\n",
            "\n",
            "get-pip.py          100%[===================>]   2.48M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-08-07 23:16:07 (33.4 MB/s) - ‘get-pip.py’ saved [2605506/2605506]\n",
            "\n",
            "Collecting pip\n",
            "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/50/c2/e06851e8cc28dcad7c155f4753da8833ac06a5c704c109313b8d5a62968a/pip-23.2.1-py3-none-any.whl.metadata\n",
            "  Downloading pip-23.2.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.2.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 3 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 1,677 kB of archives.\n",
            "After this operation, 8,965 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.1 [339 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.3 [1,305 kB]\n",
            "Fetched 1,677 kB in 1s (1,707 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-setuptools.\n",
            "(Reading database ... 120519 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.3_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.3) ...\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.2.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcsxfMJ--Pcy",
        "outputId": "9950ab84-bf5e-4f51-e2f2-bbcafca60c2f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tflearn) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tflearn) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tflearn) (9.4.0)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127282 sha256=4497014674ca058041cb56fc545f0818dd89e98743693b67460841b6e40848f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/fb/7b/e06204a0ceefa45443930b9a250cb5ebe31def0e4e8245a465\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxQGenn9bEZc",
        "outputId": "02668d04-3f7b-4187-b47c-abbe2af07322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tflearn\n",
        "import tensorflow\n",
        "import json\n",
        "import random\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = LancasterStemmer()\n",
        "\n",
        "data = pd.read_json('intents.json')\n"
      ],
      "metadata": {
        "id": "he38xc5WbIwQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the questions and answers from the json file\n",
        "\n",
        "try:\n",
        "  with open(\"data.pickle\", \"rb\") as f:\n",
        "    words, labels, training, output = pickle.load(f)\n",
        "\n",
        "except:\n",
        "  words = []\n",
        "  labels = []\n",
        "  docs_x = []\n",
        "  docs_y =[]\n",
        "\n",
        "  for intent in data[\"intents\"]:\n",
        "      for pattern in intent[\"patterns\"]:\n",
        "          wrds = nltk.word_tokenize(pattern)\n",
        "          words.extend(wrds)\n",
        "          docs_x.append(wrds)\n",
        "          docs_y.append(intent[\"tag\"])\n",
        "\n",
        "      if intent[\"tag\"] not in labels:\n",
        "          labels.append(intent[\"tag\"])\n",
        "\n",
        "  words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
        "  words = sorted(list(set(words)))\n",
        "\n",
        "  labels = sorted(labels)\n",
        "\n",
        "  training = []\n",
        "  output = []\n",
        "\n",
        "  out_empty = [0 for _ in range(len(labels))]\n",
        "\n",
        "  for x, doc in enumerate(docs_x):\n",
        "      bag = []\n",
        "      wrds = [stemmer.stem(w) for w in doc]\n",
        "\n",
        "      for w in words:\n",
        "          if w in wrds:\n",
        "              bag.append(1)\n",
        "          else:\n",
        "              bag.append(0)\n",
        "      output_row = out_empty[:]\n",
        "      output_row[labels.index(docs_y[x])] = 1\n",
        "\n",
        "      training.append(bag)\n",
        "      output.append(output_row)\n",
        "\n",
        "  training = np.array(training)\n",
        "  output = np.array(output)\n",
        "\n",
        "  with open(\"data.pickle\", \"wb\") as f:\n",
        "      pickle.dump((words, labels, training, output), f)\n"
      ],
      "metadata": {
        "id": "ADbNrFLebSE5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training the model**\n",
        "\n",
        "- For training, we will use the Deep Neural Network from tflearn module.\n",
        "- We have a total of 4 layers where the first layer is the input layer, the last one id the output layer and the moddle ones are the hidden layers each with 8 neurons.\n",
        "- In each layer, all neurons are interconnected, forming a 'Fully Connected' architecture where every neuron is linked to all neurons in the subsequent layer."
      ],
      "metadata": {
        "id": "acuAZVu9V0Dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model using different layers\n",
        "\n",
        "tensorflow.compat.v1.reset_default_graph()\n",
        "\n",
        "\n",
        "net = tflearn.input_data(shape=[None, len(training[0])])\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, len(output[0]), activation='softmax')\n",
        "net = tflearn.regression(net)\n",
        "\n",
        "model = tflearn.DNN(net)\n",
        "\n",
        "model.fit(training, output, n_epoch=500, batch_size=9, show_metric=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdVenieybVpO",
        "outputId": "9d6f5bcb-8a63-4674-a4f0-a543da6887ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Step: 2499  | total loss: \u001b[1m\u001b[32m0.04509\u001b[0m\u001b[0m | time: 0.025s\n",
            "| Adam | epoch: 500 | loss: 0.04509 - acc: 1.0000 -- iter: 36/38\n",
            "Training Step: 2500  | total loss: \u001b[1m\u001b[32m0.04567\u001b[0m\u001b[0m | time: 0.032s\n",
            "| Adam | epoch: 500 | loss: 0.04567 - acc: 1.0000 -- iter: 38/38\n",
            "--\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bag_of_words(s, words):\n",
        "  bag = [0 for _ in range(len(words))]\n",
        "\n",
        "  s_words = nltk.word_tokenize(s)\n",
        "  s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
        "\n",
        "  for se in s_words:\n",
        "    for i, w in enumerate(words):\n",
        "      if w == se:\n",
        "        bag[i] = 1\n",
        "  return np.array(bag)"
      ],
      "metadata": {
        "id": "DG9Rk9FPnWEA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat():\n",
        "  print(\"Start chatting with the bot or QUIT to stop\")\n",
        "\n",
        "  while True:\n",
        "    inp = input(\"You: \")\n",
        "    if inp.lower() == \"quit\":\n",
        "      print(\"Thank you for your time. Have a nice dasy!\")\n",
        "      break\n",
        "\n",
        "    results = model.predict([bag_of_words(inp, words)])[0]\n",
        "    results_index = np.argmax(results)\n",
        "    tag = labels[results_index]\n",
        "\n",
        "    if results[results_index] > 0.7:\n",
        "      for tg in data[\"intents\"]:\n",
        "        if tg['tag'] == tag:\n",
        "          responses = tg['responses']\n",
        "      print(random.choice(responses))\n",
        "\n",
        "    else:\n",
        "      print(\"I didn't understand. Please ask another question.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdXh5CSzqhm-",
        "outputId": "aeb368f6-6fca-4d56-c1a3-9d251a20f5ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start chatting with the bot or QUIT to stop\n",
            "You: hi\n",
            "Nice to meet you!\n",
            "You: what is your name\n",
            "My name is Jay.\n",
            "You: what is your age\n",
            "23 years young!\n",
            "You: List some of the programming languages you are familiar with\n",
            "In the field of Data Science and Machine Learning, I possess expertise in several programming languages. Among them, I excel in Python, C, C++, Java, R, MATLAB, MySQL, and MySQLite. \n",
            "You: What is your proficiency in different AI/ML tools?\n",
            "Through internships and relevant coursework focused on Data Science and Machine Learning, I am proficient in Microsoft Suite, Numpy, Pandas, Matplotlib, Scikit-learn, Tensorflow, PyTorch, Keras, Spacy, NLP, and Tableau.\n",
            "You: Tell me about your work experience\n",
            "I've worked at Free Co Educations as a Data Scientist Intern and at KYC Hub as a Machine Learning Intern\n",
            "You: quit\n",
            "Thank you for your time. Have a nice dasy!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusions**\n",
        "- **Interactive Introduction:** Explore the world of conversational AI with our Python chatbot. This repository showcases a chatbot designed to introduce myself in an engaging and interactive manner. Through natural language processing, users can initiate conversations and learn about my background, education, work experiences, and more.\n",
        "\n",
        "- **Neural Network Powered:** Built on the foundation of neural networks, this chatbot demonstrates the potential of AI-driven conversations. Its neural network architecture enables smooth interactions, providing personalized responses to a variety of questions. By combining neural networks with natural language processing, the chatbot offers a seamless user experience.\n",
        "\n",
        "- **Customizable and Educational:** Feel free to customize and extend this chatbot for your own purposes. Whether you're a developer looking to learn about chatbot development or an enthusiast curious about the capabilities of AI, this repository serves as a valuable resource. Dive into the code, experiment with different responses, and gain insights into creating engaging chatbot interactions."
      ],
      "metadata": {
        "id": "5t5I1P45Xynl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Further Reading**\n",
        "- If you want to tweak some parameters in the deep neural network, you can check the link http://tflearn.org/models/dnn/\n",
        "- Here, you will find additional details regarding the hyperparameters that can be adjusted to enhance performance."
      ],
      "metadata": {
        "id": "ahjQgLnlW5zP"
      }
    }
  ]
}